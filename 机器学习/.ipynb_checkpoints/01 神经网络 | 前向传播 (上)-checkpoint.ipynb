{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 关键词：机器学习 / 神经网络\n",
    "\n",
    "太多的广告宣传他们自家的课程：手把手教你从头构建神经网络，这回小编也来蹭一波热潮，用 `numpy` 从头搭建全链接卷积神经网络，除了尽可能详细解释之外，除了代码全部公开之外，除了很想多一点文章的订阅和分享量之外（不小心说出来），教程还免费！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "zh-cn"
   },
   "source": [
    "# 简介\n",
    "人工神经网络起源于1943年。但是，由于当时的计算机性能较差，这项研究就停滞了。随着计算机技术的升级，人们发明了多种策略来优化网络。`反向传播`（`Back propagation`）是当时发展起来的最聪明的想法之一。发明人是著名教授杰弗里·欣顿。如今，该技术已成为现代神经网络中公认的方法。\n",
    "\n",
    "![neuron.png](pics/neuron.png)\n",
    "\n",
    "神经网络是从生物大脑中获得的。细胞将电子信号作为输入。经过一些非线性处理后，该单元会生成一个输出到其相邻单元。人工神经网络的工作原理类似于自然界神经网络，其中非线性的部分是由激活函数完成的。\n",
    "\n",
    "随着网络的深入设计，分类任务的准确性提高了。在2012年代，新算法`AlexNet`在世界范围的图像分类竞赛中击败了其他算法。因此，人工神经网络时代开始了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# 1. Neurons\n",
    "In the field of computer science, neuron is defined as a mechanism that takes one number as input and output another number with certain designed procedure. The procedure can be either a linear function or a non-linear function. Because one neuron is the smallest unit of a network, we normally define the function in a simplest way such that:\n",
    "\n",
    "$$\n",
    "\\mathop{neuron}(x) = x\\cdot w + b\n",
    "$$\n",
    "\n",
    "where w is called weight and b is called bias. However, if there are more than one number that need to be processed, we will need to create the same quantity of neurons to process the data at once. A 1D matrix turns out to be a good tool to calculate all the compacted data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "zh-cn"
   },
   "source": [
    "# 1.神经元\n",
    "在计算机科学领域，神经元被定义为一种以一定数量的程序以一个数字作为输入并输出另一个数字的机制。该过程可以是线性函数也可以是非线性函数。因为一个神经元是网络的最小单位，所以我们通常以最简单的方式定义函数，使得：\n",
    "\n",
    "$$\n",
    "\\mathop{neuron}(x) = x\\cdot w + b\n",
    "$$\n",
    "\n",
    "其中w称为权重，b称为偏差。但是，如果需要处理的数目不止一个，那么我们将需要创建相同数量的神经元来立即处理数据。一维矩阵被证明是计算所有压缩数据的好工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "![nn_fc.jpg](pics/nn_fc.jpg)\n",
    "\n",
    "以上图为例，每个像素用一个数字表示。如果要用一张图像作为神经网络的输入，则需要$8\\times8$神经元保存每个数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  2.  9. 15. 14.  9.  3.  0.]\n",
      " [ 0.  4. 13.  8.  9. 16.  8.  0.]\n",
      " [ 0.  0.  0.  6. 14. 15.  3.  0.]\n",
      " [ 0.  0.  0. 11. 14.  2.  0.  0.]\n",
      " [ 0.  0.  0.  2. 15. 11.  0.  0.]\n",
      " [ 0.  0.  0.  0.  2. 15.  4.  0.]\n",
      " [ 0.  1.  5.  6. 13. 16.  6.  0.]\n",
      " [ 0.  2. 12. 12. 13. 11.  0.  0.]] \n",
      "\n",
      "Label: 3 \n",
      "Shape: 8 x 8\n"
     ]
    }
   ],
   "source": [
    "nums_8x8 = load_digits()\n",
    "print(nums_8x8.images[13], '\\n\\nLabel: {}'.format(nums_8x8.target[13]),\n",
    "      '\\nShape: {} x {}'.format(nums_8x8.images.shape[1],\n",
    "                                nums_8x8.images.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "zh-cn"
   },
   "source": [
    "## 1-1. 改变形状\n",
    "图像被包含在一个矩阵中，矩阵不满足一维神经元的输入要求。我们需要将该矩阵的形状改变为为$1\\times n$矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  2.  9. 15. 14.  9.  3.  0.  0.  4. 13.  8.  9. 16.  8.  0.  0.  0.\n",
      "   0.  6. 14. 15.  3.  0.  0.  0.  0. 11. 14.  2.  0.  0.  0.  0.  0.  2.\n",
      "  15. 11.  0.  0.  0.  0.  0.  0.  2. 15.  4.  0.  0.  1.  5.  6. 13. 16.\n",
      "   6.  0.  0.  2. 12. 12. 13. 11.  0.  0.]] \n",
      "\n",
      "Shape: 1 x 64\n"
     ]
    }
   ],
   "source": [
    "print(nums_8x8.images[13].reshape(1, -1), \n",
    "      '\\n\\nShape: 1 x {}'.format(nums_8x8.images.shape[1] *\n",
    "                                 nums_8x8.images.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "zh-cn"
   },
   "source": [
    "## 1-2. 权重与偏差\n",
    "根据图示，下一层输入的维数是32。我们需要一个$64\\times 32$ 2D矩阵将$1\\times 64$维矩阵转换为$1\\times 32$维的矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: 64 x 32\n"
     ]
    }
   ],
   "source": [
    "w = np.random.normal(0, 1, 64*32).reshape(64, 32)\n",
    "print('Shape: {} x {}'.format(w.shape[0], w.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.dot(nums_8x8.images[13].reshape(1, -1), w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -72.75  104.19  -28.75  124.42   59.     39.84  -86.92   27.6   -60.53\n",
      "    51.99  -45.77  132.61   35.35   -4.97   68.29   18.75  -69.75  -88.27\n",
      "  -124.26   -2.95  -75.69   58.55  -27.45  -40.3     4.42   92.63  -47.17\n",
      "    27.93  -45.07   43.18  159.59   30.43]] \n",
      "\n",
      "Shape: 1 x 32\n"
     ]
    }
   ],
   "source": [
    "print(np.round(x, decimals=2), '\\n\\nShape: 1 x {}'.format(x.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "zh-cn"
   },
   "source": [
    "除权重矩阵外，我们还需要补充一个术语：`偏差`。\n",
    "有两种向矩阵添加偏差的方法：\n",
    "1. 创建另一个$1\\times n$矩阵以添加到$x\\cdot w$上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -71.75  105.19  -27.75  125.42   60.     40.84  -85.92   28.6   -59.53\n",
      "    52.99  -44.77  133.61   36.35   -3.97   69.29   19.75  -68.75  -87.27\n",
      "  -123.26   -1.95  -74.69   59.55  -26.45  -39.3     5.42   93.63  -46.17\n",
      "    28.93  -44.07   44.18  160.59   31.43]]\n"
     ]
    }
   ],
   "source": [
    "x = x + np.ones((1, 32))\n",
    "print(np.round(x, decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "zh-cn"
   },
   "source": [
    "2. 向输入神经元以及权重矩阵各增加一个维度，并将所有值设为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -71.75  105.19  -27.75  125.42   60.     40.84  -85.92   28.6   -59.53\n",
      "    52.99  -44.77  133.61   36.35   -3.97   69.29   19.75  -68.75  -87.27\n",
      "  -123.26   -1.95  -74.69   59.55  -26.45  -39.3     5.42   93.63  -46.17\n",
      "    28.93  -44.07   44.18  160.59   31.43]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(\n",
    "    np.dot(np.hstack([nums_8x8.images[13].reshape(1, -1), [[1]]]), \n",
    "           np.vstack([w, np.ones(w.shape[1])])), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "zh-cn"
   },
   "source": [
    "从理论上讲，这两种方法都能提供相同的结果，但是大多数人都喜欢第一种方法。诸如`tensorflow`和`pytorch`之类的流行框架也仅提供$1^{st}$方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "zh-cn"
   },
   "source": [
    "# 2. 初始化\n",
    "在上一节中，权重矩阵是通过正态分布随机生成的。显然，这不是初始化矩阵的唯一方法。有各种各样的分布或函数可以生成数字。常见的方法包括：\n",
    "1. 均匀分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31 0.82 0.44 0.41 0.75 0.77 0.34 0.75 0.36 0.45 0.99 0.05]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.random.uniform(0, 1, 12), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.32 -1.04 -0.28 -0.36 -0.56  0.31  0.26  0.67 -0.73 -0.12  0.67 -0.86]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.random.normal(0, 0.5, 12), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "zh-cn"
   },
   "source": [
    "3. Xavier初始化 <[论文链接](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)>\n",
    "4. 他初始化<[论文链接](https://arxiv.org/pdf/1502.01852.pdf)>\n",
    "\n",
    "$3^{rd}$和$4^{th}$方法是高级的初始化方法，它们可以帮助获得更好的训练结果。有关更多详细信息，您可以相应地查看相关论文。\n",
    "\n",
    "# 阶段总结\n",
    "理解了初始化和矩阵相乘之后，我们就能非常直观的定义神经网络的`层`结构，并把它规范的写成功能函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(x, insize, outsize):\n",
    "    # Initialize weights & bias.\n",
    "    w = np.random.normal(0, 1, insize*outsize).reshape(insize, outsize)\n",
    "    b = np.ones((1, outsize))\n",
    "    \n",
    "    # Calculate a linear function.\n",
    "    x = np.dot(x.reshape(len(x), -1), w) + b\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "zh-cn"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "zh-cn",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
